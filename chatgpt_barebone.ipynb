{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up env variables (e.g. in a .env file if using vscode)\n",
    "\n",
    "- \"KEY\", for your openai API key\n",
    "- \"PROMPT_SYSTEM\" (optionally) if you want to give your chatbot a default personality (e.g. helpful expert in area x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "\n",
    "#%pip install openai\n",
    "#%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import openai\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "#api key\n",
    "openai.api_key = os.getenv(\"KEY\")\n",
    "#default personality / behavior\n",
    "default_system = os.getenv(\"PROMPT_SYSTEM\") \n",
    "\n",
    "if (default_system is not None):\n",
    "    #initializing chat history with the system prompt\n",
    "    conversation = [{\"role\": \"system\", \"content\": default_system}]\n",
    "else:\n",
    "    conversation = []\n",
    "    \n",
    "#the maximum context window (short term memory) is 4096 tokens, so we need to keep track of token usage to limit the risk running into an API error; the webUI is using a sliding window to manage around this limit\n",
    "token_count = 0\n",
    "\n",
    "\n",
    "#API calls to OpenAI\n",
    "def get_gpt (prompt):\n",
    "    global token_count\n",
    "    global conversation\n",
    "\n",
    "    #if our current token_count is above 3000 then we remove the oldest message from the conversation, if there is a personality set up in default_system then the 2nd oldest\n",
    "    if token_count > 3000:\n",
    "        if (default_system is not None):\n",
    "            conversation.pop(1)\n",
    "        else:\n",
    "            conversation.pop(0)\n",
    "\n",
    "    conversation.append({\"role\": \"user\", \"content\": prompt})\n",
    "    response = openai.ChatCompletion.create(\n",
    "            #gpt-3.5-turbo is the current equivalent of what's behind the web UI\n",
    "            model=\"gpt-3.5-turbo\", \n",
    "            messages=conversation,\n",
    "            #the higher the temperature the more creative / diverse the responses will be, minimum is 0 (deterministic), maximum is currently 2 (too much)\n",
    "            temperature = 0.3,\n",
    "            max_tokens = 1000,\n",
    "            n = 1            \n",
    "        )\n",
    "    message = response.choices[0].message.content\n",
    "    token_count = response.usage.total_tokens\n",
    "\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": message})\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da5b359509b4cb892dd2acf0dc08bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_rigâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current token count:  111\n",
      "current token count:  818\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import ipywidgets as widgets\n",
    "\n",
    "html_template = \"\"\"\n",
    "<div>\n",
    "    <pre>\n",
    "        <div>{}</div>\n",
    "        <div>{}</div>\n",
    "    </pre>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "#displaying messages\n",
    "def render_message(message):\n",
    "    if message[\"role\"] == \"assistant\":\n",
    "        return(f\"<i>ChatGPT</i>: {message['content']}\")\n",
    "    else:\n",
    "        return(f\"<b>You</b>: {message['content']}\")\n",
    "    \n",
    "\n",
    "# Define a function to handle user input\n",
    "def handle_input(button):\n",
    "    user_input = input_widget.value\n",
    "    output.append_display_data(\"--------------message sent--------------\")\n",
    "    input_widget.value = ''\n",
    "    \n",
    "    response = get_gpt(user_input)\n",
    "    latest_messages = html_template.format(render_message(conversation[-2]),render_message(conversation[-1]))\n",
    "    output.append_display_data(HTML(latest_messages))\n",
    "\n",
    "    print('current token count: ', token_count)\n",
    "    \n",
    "def get_bigger(args):        \n",
    "    input_widget.rows = input_widget.value.count('\\n') + 4\n",
    "\n",
    "output = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "input_widget = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Type your message here...',\n",
    "    description='Input:',\n",
    "    disabled=False,\n",
    "    layout={'width': '100%', 'height': 'auto'},\n",
    "    rows = 5\n",
    ")\n",
    "\n",
    "input_widget.observe(get_bigger,'value')\n",
    "\n",
    "# Create a button to send the input\n",
    "send_button = widgets.Button(description='Send', layout={'width': '100%'})\n",
    "send_button.on_click(handle_input)\n",
    "\n",
    "# Display the input widget and send button\n",
    "display(widgets.VBox([output,input_widget,send_button]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
