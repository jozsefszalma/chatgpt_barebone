{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up env variables (e.g. in a .env file if using vscode)\n",
    "\n",
    "- \"KEY\", for your openai API key\n",
    "- \"PROMPT_SYSTEM\" (optionally) if you want to give your chatbot a default personality (e.g. helpful expert in area x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"KEY\")\n",
    "default_system = os.getenv(\"PROMPT_SYSTEM\") \n",
    "\n",
    "conversation = [{\"role\": \"system\", \"content\": default_system}]\n",
    "\n",
    "def display_message(message):\n",
    "    if message[\"role\"] == \"assistant\":\n",
    "        print(f\"ChatGPT: {message['content']}\")\n",
    "    else:\n",
    "        print(f\"You: {message['content']}\")\n",
    "\n",
    "def get_gpt (prompt):\n",
    "    conversation.append({\"role\": \"user\", \"content\": prompt})\n",
    "    response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=conversation,\n",
    "            temperature = 0.3,\n",
    "            max_tokens = 3000,\n",
    "            n = 1            \n",
    "        )\n",
    "    message = response.choices[0].message.content\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": message})\n",
    "    return message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: explain the concept of pytorch data loader class please\n",
      "ChatGPT: Sure thing! In PyTorch, the `DataLoader` class is used to load and iterate over datasets during the training or testing process. It is a built-in PyTorch class that provides an efficient way to load data in parallel using multiprocessing.\n",
      "\n",
      "The `DataLoader` class takes in a dataset object and a batch size as input. It then divides the dataset into smaller batches of the specified size and loads them into memory. This helps to reduce memory usage and speeds up the training process.\n",
      "\n",
      "The `DataLoader` class also provides several other useful features, such as shuffling the data, dropping the last batch if it is smaller than the specified batch size, and loading the data in parallel using multiple worker processes.\n",
      "\n",
      "Overall, the `DataLoader` class is a powerful tool for efficiently loading and iterating over large datasets in PyTorch.\n",
      "ChatGPT: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"bye\", \"goodbye\", \"exit\"]:\n",
    "        print(\"ChatGPT: Goodbye!\")\n",
    "        break\n",
    "    response = get_gpt(user_input)\n",
    "    display_message(conversation[-2])\n",
    "    display_message(conversation[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
